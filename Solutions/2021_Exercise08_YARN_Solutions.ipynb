{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_Exercise08_YARN_Solutions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm4hlcLLkigJ"
      },
      "source": [
        "# <center>Big Data for Engineers – Solutions</center>\n",
        "## <center>Spring 2020 – Week 8 – ETH Zurich</center>\n",
        "## <center>YARN</center>\n",
        "\n",
        "# What is YARN?\n",
        "\n",
        "\n",
        "Fundamentally, “**Y**et **A**nother **R**esource **N**egotiator”. **YARN**  is a resource management systems designed to work on existing and new Hadoop clusters. \n",
        "\n",
        "YARN supports pluggable schedulers. The task of the scheduler is to share the resources of a large cluster among different tenants (applications) while trying to meet application demands (memory, CPU). A user may have several applications active at a time. \n",
        "\n",
        "As mentioned in the lecture, this week's exercise will **not** focus on how the scheduling happens inside YARN, i.e., in which order and how the apllications are launched. This is out of the scope of this lecture. The important content of this exercise is the architecture of YARN and how the resource manager, application masters and namenodes interact. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuQxO1dL32EY"
      },
      "source": [
        "### 0 (Warm up) – Different resources\n",
        "Before starting with the exercises on YARN we will recap the different resources that can be requested in a cluster. Remeber that in MapReduce v1 each map and reduce task are processed in map and reduce slots. These slots are bundles of resources. In the lecture we saw that the in YARN the solts are called containers. \n",
        "\n",
        "Name the different resources that we can request. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GeybcVo5Md-"
      },
      "source": [
        "### 0 (Warm up) – Solution\n",
        "\n",
        "We can request for different amounts of Memory (i.e., RAM) and CPU (nr. cores). The option to request disk space and  network bandwidth is still work in progress. Therefore, we usually define the resources by the need of memory and cores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqJ6pustkigP"
      },
      "source": [
        "### 1 – List at least 3 main shortcomings of MapReduce v1, which are addressed by YARN design."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-bVM6NMknn2"
      },
      "source": [
        "### 1 – Solution\n",
        "1. Scalability. YARN can scale to 10,000 nodes.\n",
        "2. Need for non-MapReduce workloads. Ability to share cluster with MPI, graph processing, and any user code.\n",
        "3. Better resource utilization. Problem with idle reducers, when mappers are not finished (and vice versa). The entire system should be used at maximum capacity when needed.\n",
        "4. Not flexible, mapper and reducer decided at configuration time\n",
        "5. Agility. Ability to maintain MapReduce frameworks of different versions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPI0HKnMmXsw"
      },
      "source": [
        "### 2 – Name at least 4 characteristics that should be fulfilled in YARN. \n",
        "(Properties not mentioned in 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfdQJ5zC0W4f"
      },
      "source": [
        "### 2 – Solution\n",
        "\n",
        "1. Scalability\n",
        "2. Multi-tenancy (Multiple clients share same application and hardware resources)\n",
        "3. Serviceability\n",
        "4. Locality awareness (for performance)\n",
        "5. High cluster utilization\n",
        "6. Reliability/Availability\n",
        "7. Secure and auditable operation\n",
        "8. Support for programming model diversity (i.e. not only MapReduce style\n",
        "communication and programming patterns)\n",
        "9. Flexible resource model (to be able to change allocated amount of resources\n",
        "to a job while running)\n",
        "10. Backwards compatibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSYF8dWhkigQ"
      },
      "source": [
        "### 3 – State which of the following statements are true:\n",
        "\n",
        "1. The ResourceManager has to provide fault tolerance for resources across the cluster \n",
        "\n",
        "1. Container allocation/deallocation can take place in a dynamic fashion as the application progresses. \n",
        "\n",
        "1. YARN plans to allow applications to only request resources in terms of memory usage and number of CPUs.\n",
        "\n",
        "1. Communications between the ResourceManager and NodeManagers are heartbeat-based. \n",
        "\n",
        "1. The ResourceManager does not have a global view of all usage of cluster resources. Therefore, it tries to make better scheduling decisions based on probabilistic prediction. \n",
        "\n",
        "1. ResourceManager has the ability to request resources back from a running application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hFptMTB00qu"
      },
      "source": [
        "### 3 – Solution\n",
        "1. **False**\n",
        "\n",
        "1. **True**\n",
        "\n",
        "1. **False**\n",
        "\n",
        "1. **True**\n",
        "\n",
        "1. **False**\n",
        "\n",
        "1. **True**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60xmGEG4kigQ"
      },
      "source": [
        "### 4 – Whose responsibility is it? Say which component of YARN is resposible for each of the following tasks (can be multiple).\n",
        "\n",
        "1. Fault Tolerance of running applications *\\[ResourceManager | ApplicationMaster | NodeManager \\]*\n",
        "\n",
        "1. Holding a two lists of valid and invalid Nodes. *\\[ResourceManager | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Asking for resources needed for an application *\\[ResourceManager | ApplicationMaster | NodeManager \\]*\n",
        "\n",
        "1. Providing leases to use containers *\\[ResourceManager | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Tracking status and progress of running applications *\\[ResourceManager | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Offers a log aggregation service that will upload data written by the application to stdout and stderr to HDFS once the application\n",
        "completes. *\\[ResourceManager | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Interacts with admin and client services. *\\[ResourceManager | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Tracking and reporting status of containers *\\[ResourceManager | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Authentication of container leases. *\\[ResourceManager | ApplicationMaster | NodeManager\\]*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB3dWbg43YeQ"
      },
      "source": [
        "### 4 – Solution\n",
        "\n",
        "1. Fault Tolerance of running applications *\\[ResourceManager | **ApplicationMaster** | NodeManager \\]*\n",
        "\n",
        "1. Holding a two lists of valid and invalid Nodes. *\\[**ResourceManager** | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Asking for resources needed for an application *\\[ResourceManager | **ApplicationMaster** | NodeManager \\]*\n",
        "\n",
        "1. Providing leases to use containers *\\[**ResourceManager** | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Tracking status and progress of running applications *\\[ResourceManager | **ApplicationMaster** | NodeManager\\]*\n",
        "\n",
        "1. Offers a log aggregation service that will upload data written by the application to stdout and stderr to HDFS once the application\n",
        "completes. *\\[ResourceManager | ApplicationMaster | **NodeManager**\\]*\n",
        "\n",
        "1. Interacts with admin and client services. *\\[**ResourceManager** | ApplicationMaster | NodeManager\\]*\n",
        "\n",
        "1. Tracking and reporting status of containers *\\[ResourceManager | **ApplicationMaster** | **NodeManager**\\]*\n",
        "\n",
        "1. Authentication of container leases. *\\[ResourceManager | ApplicationMaster | **NodeManager**\\]*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyhKKdF7kigR"
      },
      "source": [
        "### 5 – What is the typical configuration for YARN? Choose for the following components how many instances of them there are in a cluster.\n",
        "\n",
        "```\n",
        "1. ResourceManager                  a. One per cluster\n",
        "\n",
        "2. ApplicationMaster                b. One per node\n",
        "\n",
        "3. NodeManager                      c. Many per cluster, but usually not per every node\n",
        "\n",
        "4. Container                        d. Many per node \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdPd5qtE3fd-"
      },
      "source": [
        "### 5 – Solution\n",
        "1 - a  \n",
        "2 - c  \n",
        "3 - b  \n",
        "4 - d  \n",
        "\n",
        "Note that we can have multiple ApplicationMasters on the same node as long as they belong to different applications and none of them is aware about the presence of the other ApplicationMasters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqvDcKh1q1Zq"
      },
      "source": [
        "### 6 – What are ResourceRequests? What are they used for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc5hvy7H3qkr"
      },
      "source": [
        "### 6 – Solution\n",
        "\n",
        "ApplicationMasters codify their need for resources in\n",
        "terms of one or more ResourceRequests, each of which\n",
        "tracks:\n",
        "1. number of containers (e.g., 200 containers),\n",
        "2. resources8 per container h2GB RAM, 1 CPUi,\n",
        "3. locality preferences, and\n",
        "4. priority of requests within the application\n",
        "\n",
        "ResourceRequests are designed to allow users to capture\n",
        "the full detail of their needs and/or a roll-up version\n",
        "of it (e.g., one can specify node-level, rack-level, and\n",
        "global locality preferences). We see that the possibility to decide locality preferences satisfies is a key requirement for YARN to be locality aware."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD_lcE-trfHj"
      },
      "source": [
        "### 7 – What is a container launch context (ClC)? What are they used for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLQ-lwJk3sbj"
      },
      "source": [
        "### 7 – Solution\n",
        "\n",
        "All containers in YARN– including AMs– are described\n",
        "by a container launch context (CLC). This record includes a map of environment variables, dependencies stored in remotely accessible storage, security tokens, payloads for NM services, and the command\n",
        "necessary to create the process.\n",
        "\n",
        "YARN application writers submitt the application by passing a CLC or the ApplicationMaster to the Resource manager. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2CUxEz0ooV2"
      },
      "source": [
        "### 8 – Client Resource Request \n",
        "The following task concerns the process of a client requesting resources and it from the optional reading material (Murthy, A. C. (2014). Apache Hadoop YARN: Moving beyond MapReduce and Batch Processing with Apache Hadoop 2., Chapter 4). Remember that several frameworks can run on top of YARN not only MapReduce. \n",
        "\n",
        "A YARN application starts with a client resource request. \n",
        "\n",
        "\n",
        "Match the following steps to the arrows in the picture below:\n",
        "<ol type=\"a\">\n",
        "  <li>The ResourceManager will send information about the minimum and maximum capabilities of the cluster.</li>\n",
        "  <li>The ResourceManager responds to the ApplicationMaster with its assigned resources.</li>\n",
        "  <li>The client performs an application request to the Resource Manager.</li>\n",
        "  <li>The application master requests a number of containers.</li>\n",
        "  <li>The Resource Manager responds to the client with an ApplicationID with information needed to start the ApplicationMaster.</li>\n",
        "  <li>The client sends to the ResourceManager an Application Submission Context about its requirements and other necessary info.</li>\n",
        "  <li>The ResourceManager contacts the NodeManager to start the client Application Master and sends a Registration Request.</li>\n",
        "</ol>\n",
        "\n",
        "![](https://bigdata2020exassets.blob.core.windows.net/bd4e2021ex08/ClientResourceRequest.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3sm0STD3mv7"
      },
      "source": [
        "### 8 – Solution\n",
        "\n",
        "Step 1) --> c.\n",
        "\n",
        "Step 2) --> e.\n",
        "\n",
        "Step 3) --> f.\n",
        "\n",
        "Step 4) --> g.\n",
        "\n",
        "Step 5) --> a.\n",
        "\n",
        "Step 6) --> d.\n",
        "\n",
        "Step 7) --> b."
      ]
    }
  ]
}
